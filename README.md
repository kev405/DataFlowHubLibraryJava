# DataFlowHubLibraryJava
project to practice Java without frameworks

# Dominio ‚Äí Epic E1 (OOP S√≥lido)

> **Estado**: ‚úîÔ∏è _Completado_  
> **Cobertura m√≠nima garantizada**: **‚â• 70 %** instrucciones (JaCoCo)  
> **Build**: ![CI](https://github.com/tu-org/tu-repo/actions/workflows/ci.yml/badge.svg)

---

## 1. Objetivo de la √©pica

Modelar las entidades centrales del sistema aplicando buenas pr√°cticas OO:

* Encapsulaci√≥n e **inmutabilidad**
* Contratos coherentes de `equals / hashCode / toString`
* Patrones de dise√±o apropiados (Builder)
* Cobertura autom√°tica de pruebas ‚â• 70 %

---

## 2. Modelo de dominio

```mermaid
classDiagram
    direction TB

    class User {
        +UUID id
        +String name
        +String email
        +UserRole role
        +Instant createdAt
        +promoteTo()
    }

    class DataFile {
        +UUID id
        +String originalFilename
        +String storagePath
        +long sizeBytes
        +String checksumSha256
        +Instant uploadedAt
        +User uploadedBy
    }

    class BatchJobConfig {
        +UUID id
        +String name
        +String description
        +int chunkSize
        +ReaderType readerType
        +WriterType writerType
        +boolean allowRestart
        +Instant createdAt
        +boolean active
        +Builder builder()
    }

    class ProcessingRequest {
        +UUID id
        +String title
        +DataFile dataFile
        +Map\<String,String> parameters
        +RequestStatus status
        +Instant createdAt
        +User requestedBy
        +BatchJobConfig batchJobConfig
        +markRunning()/markCompleted()/markFailed()
    }

    class JobExecution {
        +UUID id
        +ProcessingRequest processingRequest
        +Instant startTime
        +Instant endTime
        +ExecutionStatus exitStatus
        +long readCount/writeCount/skipCount
        +String errorMessage
        +finish()
    }

    class Report {
        +UUID id
        +ProcessingRequest processingRequest
        +String storagePath
        +String summaryJson
        +Instant generatedAt
        +User generatedBy
    }

    User "1" --> "many" DataFile   : uploadedBy
    User "1" --> "many" ProcessingRequest : requestedBy
    DataFile "1" --> "many" ProcessingRequest : dataFile
    BatchJobConfig "1" --> "many" ProcessingRequest : template
    ProcessingRequest "1" --> "many" JobExecution  : retries
    ProcessingRequest "1" --> "0..1" Report        : result

```

---

## 3. Principios aplicados

| √Årea                 | Decisi√≥n                                                                                            |
|----------------------|------------------------------------------------------------------------------------------------------|
| **Identidad**        | Todas las entidades usan `UUID id`; igualdad y hash se basan solo en ese campo.                     |
| **Inmutabilidad**    | `DataFile` y `Report` son _records_ 100 % inmutables.<br>`User`, `ProcessingRequest`, `JobExecution` exponen solo los campos estrictamente mutables (`role`, `status`, m√©tricas). |
| **Validaciones**     | Reglas de negocio comprobadas en constructores y m√©todos de transici√≥n (`assertThrows` cubierto en tests). |
| **Cobertura**        | JaCoCo con umbral ‚â• 70 % (INSTRUCTION). El reporte HTML se publica como artefacto en GitHub Actions. |

---

## 4. Patrones usados

| Patr√≥n   | Prop√≥sito principal | Pros clave | Contras clave | D√≥nde se aplica |
|----------|--------------------|------------|---------------|-----------------|
| **Builder** | Construir objetos con muchos par√°metros opcionales manteniendo legibilidad. | Lectura fluida, evita telescoping constructors, facilita valores por defecto. | Algo de _boilerplate_ adicional. | `BatchJobConfig` (`builder(String)` + clase est√°tica `Builder`). |
| **Factory** | Ocultar o centralizar la l√≥gica de creaci√≥n cuando existen varias implementaciones o decisiones condicionales. | A√≠sla la complejidad de instanciaci√≥n; favorece SRP. | Puede dispersarse en m√∫ltiples m√©todos si crecen variantes. | **Previsto** para futuras estrategias de `ReaderType` / `WriterType` (no implementado a√∫n, documentado para epic E2). |

---

## 5. Estructura de m√≥dulos

```text
my-app
‚îú‚îÄ‚îÄ pom.xml                     # POM ra√≠z (packaging = pom)
‚îú‚îÄ‚îÄ core                        # m√≥dulo de dominio (√©pica E1)
‚îÇ   ‚îú‚îÄ‚îÄ pom.xml                 # dependencias JaCoCo, EqualsVerifier, etc.
‚îÇ   ‚îî‚îÄ‚îÄ src
‚îÇ       ‚îú‚îÄ‚îÄ main
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ java
‚îÇ       ‚îÇ       ‚îî‚îÄ‚îÄ com/practice/domain/...
‚îÇ       ‚îî‚îÄ‚îÄ test
‚îÇ           ‚îî‚îÄ‚îÄ java
‚îÇ               ‚îî‚îÄ‚îÄ com/practice/domain/...
‚îî‚îÄ‚îÄ lib                         # reservado para la √©pica E2 (utilidades)
    ‚îú‚îÄ‚îÄ pom.xml
    ‚îî‚îÄ‚îÄ src/...

```

---

## 6. C√≥mo compilar y probar

```bash
# Compilar + tests + reporte de cobertura
./mvnw clean verify

# Abrir el reporte
open core/target/site/jacoco/index.html

```

---

### InMemoryCache ‚Äì LRU

```java
import com.utils.cache.LruCache;
import java.util.Optional;
import java.util.UUID;

LruCache<UUID, User> cache = new LruCache<>(1_000);

cache.put(user.getId(), user);
Optional<User> maybe = cache.get(user.getId());

System.out.println("hits=" + cache.hitCount() + ", miss=" + cache.missCount());

```

Si insertas 1‚Äâ001 usuarios, el m√°s antiguo se descarta autom√°ticamente.

---

## 7. Dise√±o interno

| Componente      | Elecci√≥n                           | Raz√≥n                                                          |
| --------------- | ---------------------------------- | -------------------------------------------------------------- |
| Contenedor base | `LinkedHashMap` *access-order*     | Reordenamiento autom√°tico y `removeEldestEntry` para expulsi√≥n |
| Concurrencia    | `ReentrantReadWriteLock`           | Muchos lectores, un escritor                                   |
| M√©tricas        | `volatile long hitCount/missCount` | Lectura coherente sin bloqueo                                  |


---

## 8. ¬øPara qu√© sirve?

| Caso de uso                                             | Beneficio                                    |
|---------------------------------------------------------|----------------------------------------------|
| Resolver **User** por **UUID** miles de veces en un job | Reduce I/O a BD o estructuras de gran tama√±o |
| Guardar configuraciones repetidamente le√≠das            | Evita parseo / IO redundante                 |

---

## 9. LRU vs TTL (futuro)

| Estrategia | Ventaja principal                                      | Uso recomendado                                  |
| ---------- | ------------------------------------------------------ | ------------------------------------------------ |
| **LRU**    | Mantiene en memoria los elementos usados recientemente | Lecturas muy frecuentes con cache de tama√±o fijo |
| **TTL**    | Expira elementos tras X tiempo, sin importar el uso    | Configuraciones que cambian peri√≥dicamente       |

(Se incluye TtlCache<K,V> como referencia, a√∫n no productiva.)

---

### Resultados definitivos JMH (HU F1-10)

_Comando ejecutado_  
```bash
java -jar lib/target/benchmarks.jar \
     -rf CSV -rff bench.csv \
     -tu ms -f 1 -wi 2 -i 3 -w 2s -r 2s

```

| Operaci√≥n (dataset = 1 000 000) | ArrayList<br>(ms / op)  | LinkedList<br>(ms / op) | Ganador        |
| ------------------------------- | ----------------------- | ----------------------- | -------------- |
| **addLast** `list.add(x)`       | **0.000020 ¬± 0.000120** | 0.000138 ¬± 0.000025     | **ArrayList**  |
| **addFirst** `list.add(0,x)`    | 0.078022 ¬± 0.061059     | **0.000134 ¬± 0.000031** | **LinkedList** |
| **random get** `list.get(rnd)`  | **0.000025 ¬± 0.000039** | 0.625891 ¬± 2.060440     | **ArrayList**  |
| **full iteration** `for-each`   | **1.582198 ¬± 4.929957** | 3.701233 ¬± 29.944820    | **ArrayList**  |


Interpretaci√≥n r√°pida

ArrayList domina en acceso aleatorio (get), inserci√≥n al final y recorrido secuencial.

LinkedList solo gana en inserci√≥n al inicio de la lista (addFirst) con colecciones muy grandes.

Para la mayor√≠a de casos de lectura y escritura al final, ArrayList es la opci√≥n recomendada.

---

### CollectionUtils ‚Äì m√©todos con wildcards

| M√©todo | Firma | PECS aplicado |
|--------|-------|--------------|
| `copy` | `<T> List<T> copy(List<? extends T> src)` | **Producer Extends** |
| `addAll` | `<T> void addAll(Collection<? super T> dst, Collection<? extends T> src)` | **Consumer Super / Producer Extends** |
| `deepUnmodifiable` | `<K,V> Map<K,V> deepUnmodifiable(Map<? extends K,? extends V> src)` | Ambos ‚Äúextends‚Äù |

**Regla PECS**: *Producer Extends* (fuentes producen objetos ‚Üí `? extends`), *Consumer Super* (destinos consumen objetos ‚Üí `? super`).  
Esto permite una API flexible y segura, sin _casts_ ni _raw types_.

---

### Jerarqu√≠a de Excepciones

```mermaid
classDiagram
    Exception <|-- DataflowException
    DataflowException <|-- DomainException
    RuntimeException <|-- InfraException
    DomainException <|-- InvalidFileFormatException
    DomainException <|-- UserNotFoundException
    InfraException <|-- DatabaseUnavailableException

```

---

### Ejemplo de salida `ErrorHandler`

```text
[DB_DOWN] DatabaseUnavailableException: db down
com.dataflowhub.core.exception.DatabaseUnavailableException: db down
    at com.dataflowhub.core.repository.JobRepository.save(JobRepository.java:42)
    at com.dataflowhub.core.service.JobService.create(JobService.java:57)
    at ...

```

*Prefijo `[CODE]` permite dashboards r√°pidos en Kibana / Grafana.*  
Opci√≥n **verbose=false** limita a 5 l√≠neas de stack para logs limpios.

---

### Tests de Excepciones (HU F1-14)

| M√©todo bajo prueba | Excepci√≥n esperada | Test                                                                 |
|--------------------|--------------------|----------------------------------------------------------------------|
| `CsvParser.parse()`             | `InvalidFileFormatException` | `CsvParserStubTest`                                                 |
| `TtlCache.put()` (cuando falla executor) | `InfraException`              | `TtlCacheFailureTest`                                               |
| `ProcessingRequest` constructor | `NullPointerException` / `IllegalArgumentException` | `ProcessingRequestValidationTest` |

*Cada excepci√≥n declarada cuenta con al menos un test; la cobertura supera el 75 %.*  
La CI fallar√° si se cambia la excepci√≥n lanzada o se reduce la cobertura.

---

## E4 ‚Äì Concurrency Playground

### HU F1-15 ‚Äì NotificationService (ExecutorService)

```java
NotificationService svc = new NotificationService();          // 4 threads
Notification n = new Notification(user.getEmail(), "Job done");
Future<Boolean> ok = svc.send(n);

if (ok.get()) log.info("Email sent!");
svc.shutdown();
svc.awaitTermination(5, SECONDS);

```

| Criterio de aceptaci√≥n | Resultado                                           |
| ---------------------- | --------------------------------------------------- |
| 100 env√≠os en paralelo | ‚úîÔ∏è completan < 5 s sin `RejectedExecutionException` |
| `shutdown()` ordenado  | ‚úîÔ∏è termina < 2 s                                    |
| Cobertura playground   | 80 % en paquete `concurrent.notification`           |

---

### HU F1-16 ‚Äì WorkQueue (BlockingQueue)

```java
try (WorkQueue workQueue = new WorkQueue()) {
    workQueue.startWorkers(3);
    jobs.forEach(job -> workQueue.submit(() -> process(job)));
} // auto-close ‚áí stop()

```

| Ventaja          | Detalle                                                           |
| ---------------- | ----------------------------------------------------------------- |
| Distribuye carga | Productores delegan a consumidores concurrentes.                  |
| Back-pressure    | Si limitas la capacidad, `submit()` bloquea al llenar la cola.    |
| Shutdown limpio  | `stop()` env√≠a POISON PILL + `join()` sin `InterruptedException`. |

---

### HU F1-17 ‚Äì Race Condition & Fixes

| Versi√≥n | Primitiva | Resultado | Rendimiento |
|---------|-----------|-----------|-------------|
| Buggy   | `int` sin sincronizaci√≥n | Pierde incrementos | R√°pido pero incorrecto |
| Fix #1  | `AtomicInteger` | Correcto | Mejor que lock bajo contenci√≥n alta |
| Fix #2  | `ReentrantLock` | Correcto | Latencia mayor, pero permite operaciones compuestas |

**Modelo de memoria (simplificado)**  
* Escribir en un `int` no es at√≥mico ‚Üí dos hilos pueden leer-modificar-escribir simult√°neamente.  
* `AtomicInteger` ofrece operaci√≥n **CAS** -> _happens-before_ y visibilidad.  
* `ReentrantLock` establece un **monitor** ‚Üí exclusi√≥n mutua + sem√°ntica _happens-before_ en `unlock()` / `lock()`.

---

### HU F1-18 ‚Äì ReportAggregator (CompletableFuture)

```java
ReportAggregator ra = new ReportAggregator();
ra.generate("id-123")
  .thenAccept(r -> log.info("Ready: {}", r.summary()))
  .join();            // bloquea en demo; en producci√≥n, se encadena
```

| Ventaja               | Detalle                                                                     |
| --------------------- | --------------------------------------------------------------------------- |
| **Paralelismo**       | `supplyAsync` lanza tareas A, B, C en el *commonPool*; total ‚â§ m√°x(tareas). |
| **Composici√≥n**       | `thenCombine` + `thenApply` fusionan resultados sin *callback hell*.        |
| **Manejo de errores** | `exceptionally` registra con `ErrorHandler` y propaga causa unificada.      |

---

### HU F1-19 ‚Äì KPI Streams Pipeline

```java
total = transactions.stream() // fuente
.filter(t -> t.status() == VALID) // interm. 1
.collect(groupingBy( // interm. 2 + terminal
Transaction::user, summingDouble(Transaction::amount)))
.entrySet().stream() // nuevo stream
.sorted(comparingByValue().reversed())// interm. 3
.collect(toMap(..., LinkedHashMap::new));
```

| Operaci√≥n Stream | Tipo | Complejidad |
|------------------|------|-------------|
| `filter`         | intermedia | O(n) |
| `groupingBy + sum` | terminal (con cola intermedia) | O(n) |
| `sorted`         | intermedia | O(n log n) |
| `collect(toMap)` | terminal | O(n) |

**Complejidad total**: _O(n log n)_ debido a la fase de ordenaci√≥n.

---

## Streams paralelos ‚Äì Benchmark `stream()` vs `parallelStream()` (HU F1-20)

| Operaci√≥n                               | Dataset                | Secuencial (ms/op) | Paralelo (ms/op) | Speed-up |
|-----------------------------------------|------------------------|--------------------|------------------|----------|
| **Suma de 10 000 000 doubles**          | 10 M elementos         | 30.554 ¬± 3.189     | **2.764 ¬± 0.184**| **√ó 11 ‚âà** |
| **Map + reduce 100 000 JobExecution**   | 100 k elementos        | **0.076 ¬± 0.014**  | 0.083 ¬± 0.008    | √ó 0.92 (peor) |

> *Tiempos promedio (modo **AverageTime**) tras 2 warm-ups + 3 mediciones; unidad = ms/op.*

### Conclusiones r√°pidas

* **C√°lculo num√©rico masivo**  
  *La suma de 10 M doubles se acelera ‚âà 11 √ó* gracias al fork-join: cada hilo procesa unos 2,5 M elementos y la sobrecarga de divisi√≥n/combina se amortiza.

* **Datasets medianos o pipelines ligeros**  
  Map-reduce sobre 100 k objetos **empeora** en paralelo (√ó 0.92).  
  Cuando la operaci√≥n por elemento es muy barata, la sobrecarga de *fork-join* y la fusi√≥n de resultados supera al trabajo √∫til.

* **Regla pr√°ctica**  
  - Usa `parallelStream()` para colecciones **muy grandes** (‚âà > 1 M) o tareas CPU-bound costosas.  
  - Ev√≠talo en datasets peque√±os, operaciones I/O-bound o servidores donde el *commonPool* ya est√° saturado.

* **Fork-join pool**  
  `parallelStream()` utiliza el **ForkJoinPool.commonPool** (‚âà n¬∫ de n√∫cleos).  
  Puedes ajustar su tama√±o con  
  ```java
  System.setProperty("java.util.concurrent.ForkJoinPool.common.parallelism", "8");
  ```
  o emplear tu propio ForkJoinPool si necesitas aislar cargas.

  ---

  ### HU F1-21 ‚Äì Normalizaci√≥n de fechas (java.time)

```java
Instant start = job.getStartTime();           // almacenado en UTC
Duration d = TimeUtil.between(start, TimeUtil.nowUtc());
log.info("Duraci√≥n: {} s", d.getSeconds());
```

Almacena en UTC (Instant) y convierte a zona de usuario en la vista.

No se usan Date / Calendar; la API moderna es inmutable y thread-safe.

Complejidad O(1) en todas las utilidades; solo c√°lculos aritm√©ticos o acceso a campos.

---

## Optional Best Practices

| ‚úÖ DO | ‚ùå DON‚ÄôT |
|-------|---------|
| Retornar `Optional<T>` en vez de `null`. | Encadenar `Optional.get()` sin `isPresent()`. |
| Usar `map`, `flatMap`, `orElse`, `orElseThrow`. | Aceptar `Optional` como argumento p√∫blico (mejor `@Nullable` par√°metro o sobrecarga). |
| Emplear utilidades como `OptionalUtil.firstPresent(...)` para evitar cascadas de `ifPresent`. | Usar `Optional` en campos de entidad (incrementa coste de serializaci√≥n). |

> **Nota:** Guarda valores ausentes como `Optional.empty()`, no como `null` dentro del `Optional`.

Ejemplo pr√°ctico:

```java
Optional<Report> maybe = reportRepo.findByRequestId(id);
String path = maybe.map(Report::getFilePath)
                   .orElse("/placeholder.txt");
```

---

## Serializaci√≥n JSON ligera (HU F1-23)

```java
User u = ‚Ä¶;
String json = JsonSerializer.toJson(u);          // pretty-printed, null-safe
User copy  = JsonSerializer.fromJson(json, User.class);
assert u.equals(copy);
```

| Ventaja Gson core                                 | Limitaci√≥n vs Jackson                          |
| ------------------------------------------------- | ---------------------------------------------- |
| ‚âà 240 kB JAR, sin reflection module opener        | No soporta filtros, *mix-ins* o `@JsonView`    |
| Tolerancia a campos desconocidos (forward-compat) | Sin autodetecci√≥n de records en versiones < 17 |
| Rendimiento suficiente (‚âà 50 MB/s)                | Sin streaming ‚Äúpull‚Äù de bajo nivel             |

Regla adoptada: guardar JSON siempre en UTF-8, sin dependencias de Spring; los modelos evolucionan manteniendo compatibilidad porque los campos extra se ignoran.

---

### Serializaci√≥n nativa (HU F1-24) ‚Äî datos medidos

| M√©trica sobre 10 000 objetos        | JSON (Gson) | Externalizable | Ventaja |
|-------------------------------------|-------------|----------------|---------|
| **Tiempo serializar** (promedio)    | 4,01 ms/op  | **2,63 ms/op** | **‚âà 1,5 √ó** m√°s r√°pido |
| **Tiempo calcular tama√±o**<br>(`size_*` benchmark) | **0,20 ms/op** | 2,69 ms/op | JSON obtiene longitud de `String`; llamada binaria necesita copiar buffer |
| **Tama√±o total en disco** (previo)  | 250 KB      | **120 KB**     | 2,1 √ó m√°s compacto |

> _Resultados obtenidos en la misma JVM y m√°quina (cuatro n√∫cleos),  
> 3 warm-ups + 3 mediciones (`jmh` modo **AverageTime**, unidad = ms/op)._  

#### Observaciones

* **Externalizable** contin√∫a duplicando la compresi√≥n (120 KB vs 250 KB) y ahora es ~50 % m√°s veloz al serializar.  
* El benchmark `size_*` s√≥lo mide el coste de calcular el tama√±o, no el tama√±o en s√≠; por eso JSON es m√°s r√°pido ah√≠ (simple `String.length`).  
* En deserializaci√≥n (no mostrado) la tendencia es similar: binario evita parseo de texto.

#### Pros / Contras r√°pidos

| Externalizable (binario)                                | JSON (texto legible)                     |
|---------------------------------------------------------|------------------------------------------|
| ‚úî  Tama√±o m√°s peque√±o y latencia menor                  | ‚úî  Humano-legible, diff-friendly         |
| ‚úî  Controlas qu√© campos escribes (versi√≥n 100 % manual) | ‚úî  Portabilidad entre lenguajes          |
| ‚ùå  No legible / requiere versi√≥n expl√≠cita             | ‚ùå  Mayor tama√±o y parseo m√°s costoso     |

> **Regla pr√°ctica**‚ÄÇUtiliza serializaci√≥n binaria s√≥lo en caminos ¬´hot-path¬ª controlados enteramente por Java; mant√©n JSON para integraci√≥n, logs o configuraci√≥n donde la legibilidad y portabilidad pesan m√°s.

---

### CSV utilitario (HU F1-25)

```java
Path csv = Path.of("requests.csv");
CsvUtil.writeRequests(csv, list, UTF_8, ';');   // guardar
List<ProcessingRequest> back =
        CsvUtil.readRequests(csv, UTF_8, ';');  // leer
```

java.nio (Files.newBufferedReader/Writer) evita librer√≠as pesadas.

Manejo correcto de salto de l√≠nea (Windows/Linux) gracias a BufferedWriter.newLine().

Charset configurable; por defecto usamos UTF-8 para compatibilidad.

L√≥gica O(n) simple: dividir cadena + join. Para CSV complejo (citas, escapes) considerar OpenCSV / Univocity.

---

# Gu√≠a de Calidad

Herramienta | Prop√≥sito | Severidad que rompe build
------------|-----------|---------------------------
**SpotBugs** | Detecta bugs potenciales (NPE, concurrencia) | `High` o superior
**Checkstyle** | Consistencia de estilo (sangr√≠a, nombres) | `error`
**PMD** | Code smells, complejidad, duplicados | `error`

## C√≥mo suprimir un falso positivo

1. SpotBugs: a√±ade un bloque `<Match>` en `config/quality/spotbugs-exclude.xml`.
2. PMD / Checkstyle: usa la anotaci√≥n `@SuppressWarnings("PMD.RuleName")` o comentario `// CHECKSTYLE:OFF ... ON`.

> **Regla**: justificar la supresi√≥n en el PR; no silenciar globalmente.

Los reportes HTML se generan en `target/quality-reports/index.html` para cada m√≥dulo.

---

### üìö API Javadoc  
La documentaci√≥n de la API p√∫blica (‚â• 80 % cubierta) est√° disponible en  
‚û°Ô∏è [docs/javadoc/index.html](docs/javadoc/index.html)

---

# Fase 1 ‚Äì Resumen General

## Objetivos cumplidos
- ‚òëÔ∏è **Setup** multi-m√≥dulo (`core`, `lib`) con CI y cobertura ‚â• 75 %.
- ‚òëÔ∏è **Dominio** modelado (User, DataFile, ProcessingRequest, ‚Ä¶) aplicando OOP s√≥lido.
- ‚òëÔ∏è **Colecciones & Gen√©ricos**: `PagedResult<T>`, `InMemoryCache`, micro-benchmark ArrayList vs LinkedList.
- ‚òëÔ∏è **Concurrencia b√°sica**: `NotificationService`, `WorkQueue`, demo de *race-condition* y `CompletableFuture`.
- ‚òëÔ∏è **Streams & Lambdas**: `KpiCalculator`, benchmark `parallelStream()`.
- ‚òëÔ∏è **I/O & Serializaci√≥n**: JSON ‚Äúligero‚Äù, `Externalizable`, `CsvUtil` con `java.nio`.
- ‚òëÔ∏è **Calidad transversal**: an√°lisis est√°tico (SpotBugs, Checkstyle, PMD), JMH, Javadoc 80 %.

---

## Conceptos practicados
- **OOP** (encapsulaci√≥n, inmutabilidad, patr√≥n Builder/Factory).  
- **Streams & Collectors** (`groupingBy`, `mapping`, paralelos).  
- **Generics avanzados** (wildcards `? extends / super`).  
- **Concurrencia** (`ExecutorService`, `BlockingQueue`, `AtomicInteger`, `ReentrantLock`).  
- **java.time** (`Instant`, `LocalDate`, zonas).  
- **Optional** (best practices, utilidades).  
- **I/O / NIO.2** (Paths, Files, charsets).  
- **Benchmarking** (JMH).  
- **Calidad** (JaCoCo, SpotBugs, Checkstyle, PMD).  
- **Javadoc** generada y publicada.  

---

## Principales aprendizajes
1. **Trade-offs en estructuras de datos** ‚Äì benchmark mostr√≥ cu√°ndo `LinkedList` vence a `ArrayList` solo en inserciones al inicio con datasets grandes.  
2. **Overhead de `parallelStream()`** ‚Äì speed-up real s√≥lo con > 1 M elementos CPU-bound.  
3. **Externalizable vs JSON** ‚Äì binario 2√ó m√°s peque√±o y r√°pido, pero pierde portabilidad/legibilidad.  
4. **Evitar *data races*** ‚Äì `AtomicInteger` ofrece CAS barato; locks √∫tiles para operaciones compuestas.  
5. **Calidad automatizada** ‚Äì build falla temprano; menor tiempo de revisi√≥n manual.

---

## Gaps / dificultades detectadas
- Necesidad de profundizar en **JMH avanzado** (profiler, warm-up adecuado).  
- PMD marc√≥ complejidad > 15 en algunos m√©todos; pendiente refactorizar.  
- Cobertura JaCoCo de *benchmarks* excluida; explorar integraci√≥n con `jacoco:agent` para medici√≥n real.  
- Falta prueba de integraci√≥n end-to-end (JSON ‚Üî CSV ‚Üî Report).

---

## Pr√≥ximos pasos (Fase 2)
| √Årea | Acci√≥n | Enlace |
|------|--------|--------|
| **Refactor** | Reducir complejidad de `ProcessingRequest.Builder`. | #REF-TICKET-123 |
| **Performance** | A√±adir benchmarks para *I/O* (Buffered vs NIO channels). | perf-board |
| **Observabilidad** | Integrar logs estructurados + metrics Micrometer. | board-fase-2 |
| **Persistencia** | Prototipo con Spring Batch + H2. | board-fase-2 |
| **Automatizaci√≥n** | Publicar *GitHub Pages* con Javadoc y JaCoCo badge. | PR #XYZ |

> **Cobertura actual:** 78 % (core) ‚Ä¢ 85 % (lib)  
> **Benchmarks clave:** *externalizable vs JSON* (√ó1.5 speed-up) / *parallelStream suma* (√ó11 speed-up).

---

_Fase 1 establecida como base s√≥lida; lista para escalar a integraci√≥n, observabilidad y optimizaci√≥n avanzada en la siguiente etapa._

---

# DataFlowHubLibraryJava ‚Äì Fase 2 (√âpica B0)

> **Boot Setup & Tooling**
> **Estado**: ‚úÖ F2-01 ‚Ä¢ ‚úÖ F2-02 ¬∑ ‚úÖ F2-03

Este documento resume los cambios y lineamientos aplicados en la **Fase 2** para preparar el andamiaje de Spring Boot y conectar la librer√≠a de la Fase 1 con un servicio API.

---

## 1) Estructura del repositorio (multi-m√≥dulo)

```
DataFlowHubLibraryJava/
‚îú‚îÄ pom.xml                    # POM padre (packaging = pom)
‚îú‚îÄ lib/                       # utilidades/demos (Fase 1)
‚îÇ  ‚îî‚îÄ pom.xml
‚îú‚îÄ core/                      # l√≥gica reusable de dominio (Fase 1)
‚îÇ  ‚îî‚îÄ pom.xml
‚îî‚îÄ api-service/               # NUEVO: servicio REST Spring Boot 3
   ‚îî‚îÄ pom.xml
```

**Claves del POM padre**

* Propiedad centralizada `spring.boot.version`.
* Import del **BOM** de Spring Boot en `<dependencyManagement>`.
* Versi√≥n del **spring-boot-maven-plugin** fijada en `<pluginManagement>` para herencia en todos los m√≥dulos.

---

## 2) HU **F2-01 ‚Äì Setup de Spring Boot**

**Objetivo:** Inicializar un servicio web m√≠nimo con Spring Boot 3 (Web + Actuator) que compile y arranque.

**Entregables**

* M√≥dulo **`api-service`** creado.
* Dependencias: `spring-boot-starter-web`, `spring-boot-starter-actuator`.
* Configuraci√≥n de versi√≥n de Boot mediante BOM en el POM padre.

**Criterios de aceptaci√≥n**

* `mvn -pl api-service test` compila sin errores.
* La aplicaci√≥n arranca localmente.

**Comandos**

```bash
mvn -pl api-service test
mvn -pl api-service spring-boot:run
```

---

## 3) HU **F2-02 ‚Äì Importar `core-lib` como dependencia**

**¬øQu√© se hizo?**

1. Se import√≥ el m√≥dulo **`core`** (librer√≠a de Fase 1) dentro de **`api-service`**:

   ```xml
   <dependency>
     <groupId>com.practice</groupId>
     <artifactId>core</artifactId>
     <version>${project.version}</version>
   </dependency>
   ```
2. Se habilit√≥ *component scan* cruzado desde la app web para detectar beans del `core`:

   ```java
   @SpringBootApplication(scanBasePackages = "com.practice")
   public class ApiServiceApplication { }
   ```
3. Se valid√≥ la inyecci√≥n de un bean de la librer√≠a (ej. `ErrorHandler`) exponiendo un endpoint de prueba:

   ```java
   @RestController
   @RequiredArgsConstructor
   class HealthExtraController {
     private final ErrorHandler errorHandler; // viene de core
     @GetMapping("/ping") public String ping() { return "pong"; }
   }
   ```

**Criterios de aceptaci√≥n**

* `mvn -pl api-service test` pasa sin errores.
* `ErrorHandler` (u otro bean de `core`) se inyecta y funciona en un endpoint expuesto.

**Probar r√°pidamente**

```bash
mvn clean install
java -jar api-service/target/api-service-*.jar
# En otra terminal
curl http://localhost:8080/actuator/health
curl http://localhost:8080/ping     # ‚Üí "pong"
```

---

## 4) Configuraci√≥n Maven aplicada (resumen)

**POM padre**

* Define:

    * `java.version`
    * `spring.boot.version`
* Importa el BOM de Spring Boot en `dependencyManagement`.
* Fija `spring-boot-maven-plugin` en `pluginManagement` (heredado por los m√≥dulos).
* Orden de m√≥dulos para un build determinista:

  ```xml
  <modules>
    <module>lib</module>
    <module>core</module>
    <module>api-service</module>
  </modules>
  ```

---

## 5) C√≥mo compilar y ejecutar

**Compilaci√≥n completa**

```bash
mvn clean install
```

**Compilar solo `api-service` (con sus dependencias aguas arriba)**

```bash
mvn -pl api-service test -am
```

**Ejecutar**

```bash
java -jar api-service/target/api-service-*.jar
```

**Endpoints**

* `GET /actuator/health`
* `GET /ping`

---

# HU F2-03 ‚Äì Perfiles `dev`, `test`, `prod`

> **Objetivo**: definir configuraci√≥n por ambiente en `api-service`, aislando datasources y niveles de log, y documentar c√≥mo activar perfiles.

---

## Archivos creados/actualizados

* `api-service/src/main/resources/application.yml` *(base)*
* `api-service/src/main/resources/application-dev.yml`
* `api-service/src/main/resources/application-test.yml`
* `api-service/src/main/resources/application-prod.yml`

**Dependencias relevantes (en ********************`api-service/pom.xml`********************):** `spring-boot-starter-jdbc`, `com.h2database:h2` *(runtime)*, `org.postgresql:postgresql` *(runtime)*.
**Tests** ejecutan con perfil `test` de forma autom√°tica (Surefire: `spring.profiles.active=test`).

---

## Configuraci√≥n base (`application.yml`)

```yaml
spring:
  application:
    name: api-service
  profiles:
    default: dev    # si no se especifica, arranca en dev
server:
  port: 8080
management:
  endpoints:
    web:
      exposure:
        include: health,info
```

---

## Perfil `dev` (`application-dev.yml`)

```yaml
spring:
  datasource:
    url: jdbc:h2:mem:dataflow;DB_CLOSE_DELAY=-1;MODE=PostgreSQL
    driver-class-name: org.h2.Driver
    username: sa
    password:
  h2:
    console:
      enabled: true

logging:
  level:
    root: INFO
    com.practice: DEBUG
```

## Perfil `test` (`application-test.yml`)

```yaml
spring:
  datasource:
    url: jdbc:h2:mem:testdb;DB_CLOSE_DELAY=-1;MODE=PostgreSQL
    driver-class-name: org.h2.Driver
    username: sa
    password:
  jpa:
    hibernate:
      ddl-auto: create-drop

logging:
  level:
    root: WARN
    org.springframework: WARN
```

## Perfil `prod` (`application-prod.yml`)

```yaml
spring:
  datasource:
    url: ${DB_URL:jdbc:postgresql://db:5432/dataflow}
    username: ${DB_USER:postgres}
    password: ${DB_PASSWORD:postgres}
    driver-class-name: org.postgresql.Driver
  jpa:
    hibernate:
      ddl-auto: validate

server:
  port: ${PORT:8080}

logging:
  level:
    root: INFO
    org.springframework: INFO
  file:
    name: ${LOG_FILE:logs/api-service.log}
```

---

## C√≥mo activar perfiles

* **Por variable de entorno**

  ```bash
  # Linux/Mac
  SPRING_PROFILES_ACTIVE=prod mvn -pl api-service spring-boot:run

  # Windows PowerShell
  $Env:SPRING_PROFILES_ACTIVE="prod"; mvn -pl api-service spring-boot:run
  ```
* **Por l√≠nea de comandos al ejecutar el JAR**

  ```bash
  java -Dspring.profiles.active=dev -jar api-service/target/api-service-*.jar
  ```
* **Tests**: el plugin Surefire fija `spring.profiles.active=test` (no requiere anotaciones en los tests).

---

## Verificaci√≥n r√°pida

```bash
mvn clean install
java -jar api-service/target/api-service-*.jar
# En otra terminal
curl http://localhost:8080/actuator/health
curl http://localhost:8080/ping   # si est√° habilitado el endpoint de ejemplo
```

**Smoke test (resumen):** se valida que con `test` el `DataSource` sea H2 en memoria y que el nivel de log sea `WARN`.

---

## Criterios de aceptaci√≥n

* Cambiar perfil modifica datasource y nivel de log.
* Tests se ejecutan con perfil `test` autom√°ticamente (`@ActiveProfiles("test")`).
* README secci√≥n ‚ÄúPerfiles‚Äù explica variables y ejemplos.

---

# B1 ¬∑ HU F2-04 ‚Äî Endpoint **POST /files** (simular upload de `DataFile`)

> **Objetivo**: exponer un endpoint que **registre metadatos** de un archivo (NO guarda binarios), valide con **Bean Validation** y responda **201 Created** con `Location` y un DTO de salida.

---

## Archivos creados/actualizados

* `api-service/src/main/java/.../files/FileController.java`
* `api-service/src/main/java/.../files/FileUploadRequest.java`
* `api-service/src/main/java/.../files/FileUploadResponse.java`
* `api-service/src/main/java/.../common/ApiErrorHandler.java`
* `api-service/src/main/java/.../files/FileTooLargeException.java`
* `api-service/src/test/java/.../files/FileControllerTest.java`

**Dependencias** (en `api-service/pom.xml`)

* `spring-boot-starter-validation` (activaci√≥n de Bean Validation)

---

## Contrato del endpoint

**Ruta:** `POST /files`

**Request Body (JSON):**

```json
{
  "originalFilename": "ventas_julio.csv",
  "sizeBytes": 1048576,
  "storagePath": "/data/in/ventas_julio.csv",
  "checksumSha256": "9f2c...abcd", // OPCIONAL
  "uploadedByUserId": "8d3b6c3f-64db-4c1e-9d51-3b6f3d8e2a11"
}
```

**Validaciones (Bean Validation):**

* `originalFilename` ‚Üí `@NotBlank` y `@Size(max=255)`
* `sizeBytes` ‚Üí `@Positive` y **m√°x 50 MB** (`50 * 1024 * 1024`)
* `checksumSha256` ‚Üí **opcional**, regex `^[a-fA-F0-9]{64}$`
* `storagePath` ‚Üí `@NotBlank`
* `uploadedByUserId` ‚Üí `@NotNull` (UUID)

**Response (201 Created):**

* **Headers:** `Location: /files/{id}`
* **Body:**

```json
{
  "id": "4c16cf2a-9a11-4a9b-a1e5-0c7b2a7d1234",
  "originalFilename": "ventas_julio.csv"
}
```

**Errores (400 Bad Request):**

* Cuerpo est√°ndar: `{ "code": string, "message": string, "fields": [ {"field": string, "message": string} ] }`
* Tama√±o excedido ‚áí `code = "FILE_TOO_LARGE"`
* Violaciones de Bean Validation ‚áí `code = "VALIDATION_ERROR"` con `fields[]`

---

## Mapeo al dominio

* Se reutiliza el `DataFile` **existente** en `core/domain`.
* Creaci√≥n recomendada: **`DataFile.createForUpload(...)`** (f√°brica en el dominio que genera `id`/`uploadedAt` y resuelve `uploadedBy` a partir de `uploadedByUserId`).
* Si no existe la f√°brica, puede instanciarse el `DataFile` directamente respetando las invariantes actuales del dominio.

---

## Ejemplo con `curl`

```bash
# √âxito (201)
curl -i -X POST http://localhost:8080/files \
  -H 'Content-Type: application/json' \
  -d '{
        "originalFilename":"ventas_julio.csv",
        "sizeBytes":1048576,
        "storagePath":"/data/in/ventas_julio.csv",
        "uploadedByUserId":"8d3b6c3f-64db-4c1e-9d51-3b6f3d8e2a11"
      }'

# Error (400 FILE_TOO_LARGE)
curl -i -X POST http://localhost:8080/files \
  -H 'Content-Type: application/json' \
  -d '{
        "originalFilename":"big.bin",
        "sizeBytes":52428801,
        "storagePath":"/tmp/big.bin",
        "uploadedByUserId":"8d3b6c3f-64db-4c1e-9d51-3b6f3d8e2a11"
      }'

# Error (400 VALIDATION_ERROR) por filename vac√≠o + checksum inv√°lido
curl -i -X POST http://localhost:8080/files \
  -H 'Content-Type: application/json' \
  -d '{
        "originalFilename":" ",
        "sizeBytes":100,
        "checksumSha256":"XYZ",
        "storagePath":"/data/in/a.csv",
        "uploadedByUserId":"8d3b6c3f-64db-4c1e-9d51-3b6f3d8e2a11"
      }'
```

---

## Tests incluidos (`@WebMvcTest`)

* **Happy path:** 201 + `Location` + body `{id, originalFilename}`.
* **Tama√±o > 50MB:** 400 con `code=FILE_TOO_LARGE`.
* **Payload inv√°lido:** 400 `VALIDATION_ERROR`, lista de `fields` con `originalFilename` y `checksumSha256`.

> Los tests fuerzan la validaci√≥n antes de llegar al dominio usando `@Valid` + `BindingResult`.

---

## Criterios de aceptaci√≥n

* 202 con Location v√°lido al crear correctamente.
* 400 con lista de errores de validaci√≥n cuando falten campos.
* `title` recorta espacios; longitud > 140 ‚Üí 400.
* Tests de mapeo DTO‚Üídominio verifican campos obligatorios y opcionales.

---

## Notas

* El almacenamiento real del binario **no se implementa** en esta HU; solo se registran metadatos.
* En `prod` el comportamiento de logging y perfiles se hereda de la HU **F2-03**.

---

# HU F2-05 ‚Äî Endpoint **POST /processings** (ACK 202)

> **Objetivo:** aceptar la solicitud de procesamiento y devolver un **acuse (ACK)** con `status=PENDING`, sin instanciar a√∫n el agregado de dominio ni persistir. La validaci√≥n de existencia de `DataFile`, `User` y `BatchJobConfig` se realizar√° en la siguiente HU/√©pica.

---

## Archivos creados/actualizados

* `api-service/src/main/java/.../processings/ProcessingController.java`
* `api-service/src/main/java/.../processings/dto/CreateProcessingRequest.java`
* `api-service/src/main/java/.../processings/dto/ProcessingCreatedResponse.java`
* `api-service/src/main/java/.../config/AppBatchProps.java`
* `api-service/src/test/java/.../processings/ProcessingControllerTest.java`
* `api-service/src/main/resources/application.yml` ‚Üí propiedad `app.batch.default-config-id`

**Notas**

* Se reutiliza el `ApiErrorHandler` existente (`badRequestFrom(BindingResult)`) para responder **400 VALIDATION\_ERROR**.
* No se construyen objetos de dominio (`ProcessingRequest`, `DataFile`, `User`, `BatchJobConfig`) en esta HU.

---

## Contrato del endpoint

**Ruta:** `POST /processings`

**Request Body (JSON):**

```json
{
  "title": "ETL Ventas Julio",
  "dataFileId": "e4b7b32e-f93b-47b1-8a5d-6a0c3c8f1b0b",
  "requestedByUserId": "1b2b4d6e-9fa1-4f0f-8b12-33d4c9a0e111",
  "batchJobConfigId": "00000000-0000-0000-0000-000000000001", // OPCIONAL
  "parameters": { "delimiter": ";" }                          // OPCIONAL
}
```

**Validaciones:**

* `title` ‚Üí se aplica `trim()` y luego se exige longitud **1..140**. (El DTO puede permitir hasta 400 para entrada, pero el controller recorta y valida el l√≠mite efectivo.)
* `dataFileId` ‚Üí requerido (UUID)
* `requestedByUserId` ‚Üí requerido (UUID)
* `batchJobConfigId` ‚Üí **opcional**; si no llega se usa `app.batch.default-config-id`
* `parameters` ‚Üí opcional; si viene, `Map<@NotBlank String, @NotBlank String>`

**Response (202 Accepted):**

* **Headers:** `Location: /processings/{id}`
* **Body:**

```json
{ "id": "4c16cf2a-9a11-4a9b-a1e5-0c7b2a7d1234", "status": "PENDING" }
```

**Errores (400 Bad Request):**

* Cuerpo est√°ndar: `{ "code": "VALIDATION_ERROR", "message": "Invalid payload", "fields": [ {"field": "...", "message": "..."} ] }`
* Casos cubiertos: `title` vac√≠o tras `trim`, `title` > 140, `dataFileId`/`requestedByUserId` nulos, claves/valores inv√°lidos en `parameters`.

---

## Configuraci√≥n

`application.yml` (o `application-dev.yml`):

```yaml
app:
  batch:
    default-config-id: "00000000-0000-0000-0000-000000000001"
```

Habilitar properties:

```java
@EnableConfigurationProperties(AppBatchProps.class)
```

---

## Ejemplos con `curl`

```bash
# √âxito (202)
curl -i -X POST http://localhost:8080/processings \
  -H 'Content-Type: application/json' \
  -d '{
        "title":"  ETL Ventas Julio  ",
        "dataFileId":"e4b7b32e-f93b-47b1-8a5d-6a0c3c8f1b0b",
        "requestedByUserId":"1b2b4d6e-9fa1-4f0f-8b12-33d4c9a0e111",
        "parameters": {"delimiter":";"}
      }'

# Error (400 VALIDATION_ERROR) por t√≠tulo inv√°lido
d='{"title":"   ","dataFileId":"'$(uuidgen)'","requestedByUserId":"'$(uuidgen)'"}'
curl -i -X POST http://localhost:8080/processings -H 'Content-Type: application/json' -d "$d"
```

---

## Tests (`@WebMvcTest`)

* **Happy path:** 202 + `Location` + body `{id, "PENDING"}`.
* **Uso de default:** cuando `batchJobConfigId` no viene, se lee `app.batch.default-config-id`.
* **Validaci√≥n:** `title` (trim y longitud) y requeridos ‚Üí 400 `VALIDATION_ERROR` con `fields`.

---

## Criterios de aceptaci√≥n

* 202 con Location v√°lido al crear correctamente.
* 400 con lista de errores de validaci√≥n cuando falten campos.
* `title` recorta espacios; longitud > 140 ‚Üí 400.
* Tests de mapeo DTO‚Üídominio verifican campos obligatorios y opcionales.

---

## Notas

* Esta HU no verifica la existencia de DataFile, User ni BatchJobConfig; tampoco instancia ProcessingRequest. Ese wiring (lookups/repos) se aborda en la siguiente HU/√©pica.

---

# HU F2-06 ‚Äî Endpoint **GET /processings/{id}** (estado + m√©tricas)

> **Objetivo:** exponer el estado de un *processing* combinando el **`ProcessingRequest`** y su \*\*√∫ltima \*\***`JobExecution`** (si existe). Devuelve un DTO estable para el front y 404 si el id no existe.

---

## Archivos creados/actualizados

* `api-service/src/main/java/.../processings/ProcessingQueryController.java`
* `api-service/src/main/java/.../processings/dto/ProcessingStatusResponse.java`
* `api-service/src/main/java/.../processings/query/ProcessingStatusFinder.java` *(puerto de lectura)*
* `api-service/src/main/java/.../processings/query/InMemoryProcessingStatusFinder.java` *(adaptador in-memory)*
* `api-service/src/main/java/.../utils/error/ResourceNotFoundException.java` *(404)*
* `api-service/src/test/java/.../processings/ProcessingQueryControllerTest.java`
* *(opcional demo)* `api-service/src/main/java/.../config/DemoData.java` para ‚Äúsembrar‚Äù un registro al arrancar.

**Dependencias:** se reutilizan las de `api-service`. No se modifican `core` ni `lib`.

---

## Contrato del endpoint

**Ruta:** `GET /processings/{id}`

**Response 200 (JSON):**

```json
{
  "id": "7e2a1d7c-39bb-4f1a-8a55-9a2f14c47788",
  "title": "ETL Ventas Julio",
  "status": "RUNNING",
  "createdAt": "2025-08-07T03:10:21Z",
  "dataFileId": "4c16cf2a-9a11-4a9b-a1e5-0c7b2a7d1234",
  "metrics": { "readCount": 12345, "writeCount": 12280, "skipCount": 145 },
  "lastExecution": {
    "startTime": "2025-08-07T03:10:22Z",
    "endTime": null,
    "exitStatus": null,
    "errorMessage": null
  }
}
```

**Response 404:**

```json
{ "code": "NOT_FOUND", "message": "processing id not found", "fields": [] }
```

**Notas de serializaci√≥n:**

* Tiempos (`Instant`) en formato **ISO‚Äë8601 UTC** (`Z`).
* `lastExecution` es **`null`** si nunca se ha ejecutado.
* Si existe al menos una ejecuci√≥n, `metrics` refleja la √∫ltima (`read/write/skip`).

---

## DTO de salida

```java
public record ProcessingStatusResponse(
    UUID id,
    String title,
    String status,          // RequestStatus del dominio ‚Üí String
    Instant createdAt,
    UUID dataFileId,
    Metrics metrics,
    LastExecution lastExecution
) {
  public record Metrics(long readCount, long writeCount, long skipCount) {}
  public record LastExecution(Instant startTime, Instant endTime, String exitStatus, String errorMessage) {}
}
```

---

## Fuente de datos (read model)

* Se usa el puerto **`ProcessingStatusFinder`** que expone:

    * `findRequest(UUID id)` ‚Üí `Optional<ProcessingRequest>`
    * `findLastExecution(UUID processingId)` ‚Üí `Optional<JobExecution>`
* Implementaci√≥n por defecto: `InMemoryProcessingStatusFinder` (mapas concurrentes) para permitir tests y demos sin persistencia.
* **Mapeo a DTO:**

    * `id`, `title`, `status`, `createdAt` y `dataFileId` vienen de `ProcessingRequest`.
    * Si hay √∫ltima `JobExecution`: rellena `metrics` y `lastExecution` (con `exitStatus.name()`), si no, `metrics` = `0/0/0` y `lastExecution=null`.

---

## Ejemplos con `curl`

```bash
# Existe y est√° corriendo (200)
curl -s http://localhost:8080/processings/7e2a1d7c-39bb-4f1a-8a55-9a2f14c47788 | jq

# No existe (404)
curl -i http://localhost:8080/processings/00000000-0000-0000-0000-000000000000
```

---

## Tests (`@WebMvcTest`)

* **200 sin ejecuci√≥n:** `lastExecution` no presente y `metrics` en `0`.
* **200 con ejecuci√≥n:** `status` y m√©tricas correctas; `lastExecution.startTime` en ISO‚Äë8601.
* **404 inexistente:** error con `code=NOT_FOUND`.

> En los tests se **mockea** `ProcessingStatusFinder` y se construyen objetos de dominio reales (`ProcessingRequest`, `JobExecution`) para validar el mapeo.

---

## 4. Criterios de aceptaci√≥n

* 200 con DTO completo; 404 cuando `id` no existe.
* No exponer stacktraces; errores van por `RestExceptionHandler` (B3).
* Campos de fecha en **ISO‚Äë8601 UTC**.
* Tests cubren los tres escenarios.

---

## Notas

* Este read-model es **in-memory** y sirve como contrato estable. En √©picas B5/B6 se conectar√° con **Spring Batch/Actuator** para poblar las ejecuciones reales y m√©tricas.

---

# HU F2-07 ‚Äî PostgreSQL + Flyway + Testcontainers

> **Objetivo:** configurar PostgreSQL en **dev** y **tests** con migraciones **Flyway**. En tests se usa **Testcontainers** (PG real en Docker). No se modifica `core` ni `lib`.

---

## Archivos creados/actualizados

* `api-service/pom.xml` ‚Üí dependencias JPA, PostgreSQL, Flyway y Testcontainers
* `api-service/src/main/resources/application-dev.yml` ‚Üí datasource PostgreSQL (por variables de entorno)
* `api-service/src/main/resources/application-test.yml` ‚Üí sin datasource; JPA/Flyway m√≠nimos para Testcontainers
* `api-service/src/test/java/.../db/DbSmokeTest.java` ‚Üí prueba de arranque y conexi√≥n a BD
* *(opcional)* `api-service/docker-compose.yml` ‚Üí servicio PostgreSQL local para desarrollo
* *(opcional)* `src/main/resources/db/migration/*.sql` ‚Üí scripts de Flyway

**Dependencias a√±adidas (POM ********`api-service`********):**

* `spring-boot-starter-data-jpa`
* `org.postgresql:postgresql` *(runtime)*
* `org.flywaydb:flyway-core`
* `org.flywaydb:flyway-database-postgresql` *(requerido para PG 16+)*
* `org.testcontainers:junit-jupiter` *(test)*
* `org.testcontainers:postgresql` *(test)*

> Si tu BOM de Spring Boot no trae Flyway 10, fija `flyway.version` a **10.x** o usa Testcontainers con `postgres:15-alpine` (ver m√°s abajo).

---

## Configuraci√≥n por perfil

### `application-dev.yml` (PostgreSQL por variables de entorno)

```yaml
spring:
  datasource:
    url: ${DB_URL:jdbc:postgresql://localhost:5432/dataflow}
    username: ${DB_USER:app}
    password: ${DB_PASSWORD:secret}
    driver-class-name: org.postgresql.Driver
  jpa:
    hibernate:
      ddl-auto: validate
    properties:
      hibernate.jdbc.time_zone: UTC
  flyway:
    enabled: true
    locations: classpath:db/migration
    baseline-on-migrate: true
```

### `application-test.yml` (para Testcontainers)

```yaml
spring:
  jpa:
    hibernate:
      ddl-auto: none
  flyway:
    enabled: true
```

> **No** declares `spring.datasource.*` aqu√≠: Testcontainers inyecta URL/usuario/clave autom√°ticamente.

---

## Test de humo con Testcontainers

```java
@Testcontainers
@SpringBootTest
class DbSmokeTest {
  @Container
  @ServiceConnection // Spring Boot 3.1+: autoconfigura el DataSource desde el contenedor
  static PostgreSQLContainer<?> postgres = new PostgreSQLContainer<>("postgres:16-alpine");

  // Fallback si tu Boot < 3.1
  @DynamicPropertySource
  static void pgProps(DynamicPropertyRegistry r) {
    r.add("spring.datasource.url", postgres::getJdbcUrl);
    r.add("spring.datasource.username", postgres::getUsername);
    r.add("spring.datasource.password", postgres::getPassword);
  }

  @Autowired javax.sql.DataSource ds;

  @Test void contextLoads_andDatabaseIsReachable() throws Exception {
    try (var c = ds.getConnection()) { assert c.isValid(2); }
  }
}
```

**Nota Flyway:** Para PostgreSQL 16, agrega `flyway-database-postgresql`. Si usas Flyway < 10, cambia el contenedor a `postgres:15-alpine`.

---

## Ejecuci√≥n en desarrollo (dev)

### Linux/Mac

```bash
export DB_URL=jdbc:postgresql://localhost:5432/dataflow
export DB_USER=app
export DB_PASSWORD=secret
export SPRING_PROFILES_ACTIVE=dev
mvn -pl api-service spring-boot:run
```

### Windows PowerShell

```powershell
$Env:DB_URL = "jdbc:postgresql://localhost:5432/dataflow"
$Env:DB_USER = "app"
$Env:DB_PASSWORD = "secret"
$Env:SPRING_PROFILES_ACTIVE = "dev"
mvn -pl api-service spring-boot:run
```

*(Opcional)* levanta PostgreSQL con Docker:

```yaml
# api-service/docker-compose.yml
services:
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: dataflow
      POSTGRES_USER: app
      POSTGRES_PASSWORD: secret
    ports: ["5432:5432"]
    volumes: ["pgdata:/var/lib/postgresql/data"]
volumes:
  pgdata:
```

---

## Migraciones Flyway

* Coloca scripts en `src/main/resources/db/migration` con prefijos `V1__*.sql`, `V2__*.sql`, etc.
* `baseline-on-migrate: true` permite inicializar una BD vac√≠a sin errores.

---

## CI (GitHub Actions)

```yaml
- uses: actions/checkout@v4
- uses: actions/setup-java@v4
  with:
    distribution: temurin
    java-version: '17'   # o 21 si tu POM lo requiere
    cache: maven
- run: mvn -B -DskipTests=false clean verify
```

> Testcontainers usa Docker del runner autom√°ticamente; no requieres servicios extra.

---

## Criterios de aceptaci√≥n

* La app arranca en `dev` y ejecuta migraciones Flyway sin errores.
* En `test`, el contexto usa Postgres de Testcontainers autom√°ticamente.
* Logs muestran zona horaria **UTC** y `ddl-auto=validate`.


---

# HU F2-08 ‚Äî Repositorios JPA e infraestructura de persistencia

> **Objetivo:** persistir los agregados del dominio **sin anotar \*\*\*\*\*\*\*\*`core`**, creando **entidades JPA** y **repos Spring Data** en `api-service` (capa infra). Guardar `parameters` como **JSONB** y exponer consultas b√°sicas necesarias para B2.

---

## Archivos creados/actualizados

* `api-service/src/main/java/.../infra/db/converter/MapToJsonConverter.java`
* `api-service/src/main/java/.../infra/db/entity/`
  `UserEntity.java`, `DataFileEntity.java`, `BatchJobConfigEntity.java`, `ProcessingRequestEntity.java`, `JobExecutionEntity.java`, `ReportEntity.java`
* `api-service/src/main/java/.../infra/db/repo/`
  `UserRepository.java`, `DataFileRepository.java`, `BatchJobConfigRepository.java`, `ProcessingRequestRepository.java`, `JobExecutionRepository.java`, `ReportRepository.java`
* *(opcional)* `api-service/src/main/java/.../infra/db/mapper/` (MapStruct)
  `UserMapper.java`, `DataFileMapper.java`, `ProcessingRequestMapper.java`
* `api-service/src/test/java/.../infra/db/RepositoryIT.java` (tests de integraci√≥n con Testcontainers)

**Dependencias**: se reutilizan las de HU F2-07 (JPA, PostgreSQL, Testcontainers). Si usas MapStruct, a√±ade `mapstruct` + `mapstruct-processor` (annotation processor) en `api-service/pom.xml`.

---

## Estructura de paquetes

```
api-service/
 ‚îî‚îÄ src/main/java/com/practice/apiservice/infra/db/
    ‚îú‚îÄ converter/MapToJsonConverter.java
    ‚îú‚îÄ entity/
    ‚îÇ   ‚îú‚îÄ UserEntity.java
    ‚îÇ   ‚îú‚îÄ DataFileEntity.java
    ‚îÇ   ‚îú‚îÄ BatchJobConfigEntity.java
    ‚îÇ   ‚îú‚îÄ ProcessingRequestEntity.java
    ‚îÇ   ‚îú‚îÄ JobExecutionEntity.java
    ‚îÇ   ‚îî‚îÄ ReportEntity.java
    ‚îú‚îÄ repo/
    ‚îÇ   ‚îú‚îÄ UserRepository.java
    ‚îÇ   ‚îú‚îÄ DataFileRepository.java
    ‚îÇ   ‚îú‚îÄ BatchJobConfigRepository.java
    ‚îÇ   ‚îú‚îÄ ProcessingRequestRepository.java
    ‚îÇ   ‚îú‚îÄ JobExecutionRepository.java
    ‚îÇ   ‚îî‚îÄ ReportRepository.java
    ‚îî‚îÄ mapper/ (opcional)
```

> Todo cuelga de `com.practice.apiservice` para que **component-scan** los detecte sin `@EnableJpaRepositories/@EntityScan`.

---

## Entidades JPA (resumen)

* **UserEntity** ‚Üí tabla `users` (`id: uuid`, `name` opcional).
* **DataFileEntity** ‚Üí `data_files` con: `originalFilename`, `storagePath`, `sizeBytes`, `checksumSha256`, `uploadedAt`, `uploadedBy (FK ‚Üí users)`.
* **BatchJobConfigEntity** ‚Üí `batch_job_configs` con: `name`, `description`, `chunkSize`, `readerType`, `writerType`, `allowRestart`, `createdAt`, `active`.
* **ProcessingRequestEntity** ‚Üí `processing_requests` con: `title`, `dataFile (FK)`, `parameters: jsonb`, `status (enum)`, `createdAt`, `requestedBy (FK)`, `batchJobConfig (FK)`.
* **JobExecutionEntity** ‚Üí `job_executions` con: `processingRequest (FK)`, `startTime`, `endTime`, `exitStatus (enum)`, `readCount`, `writeCount`, `skipCount`, `errorMessage`.
* **ReportEntity** ‚Üí `reports` con: `processingRequest (FK)`, `storagePath`, `summaryJson (text)`, `generatedAt`, `generatedBy (FK)`.

> Todas las `@Id` son `UUID` (`columnDefinition = "uuid"`). `parameters` usa **JSONB** con el converter de abajo.

---

## Converter JSONB

`MapToJsonConverter` serializa `Map<String,String>` ‚áÑ `jsonb` usando Jackson. Se aplica en `ProcessingRequestEntity.parameters` con `@Convert(converter = MapToJsonConverter.class)` y `@Column(columnDefinition = "jsonb")`.

---

## Repositorios Spring Data (interfaz)

> No es obligatorio anotar con `@Repository` al extender `JpaRepository` (Spring Data registra el bean autom√°ticamente). Puedes anotarlo si quieres hacerlo expl√≠cito.

* `UserRepository extends JpaRepository<UserEntity, UUID>`
* `DataFileRepository extends JpaRepository<DataFileEntity, UUID>`
* `BatchJobConfigRepository extends JpaRepository<BatchJobConfigEntity, UUID>`
* `ProcessingRequestRepository extends JpaRepository<ProcessingRequestEntity, UUID>`

    * `Page<ProcessingRequestEntity> findByStatus(RequestStatus status, Pageable pageable)`
* `JobExecutionRepository extends JpaRepository<JobExecutionEntity, UUID>`

    * `Optional<JobExecutionEntity> findTop1ByProcessingRequestIdOrderByStartTimeDesc(UUID processingRequestId)`
* `ReportRepository extends JpaRepository<ReportEntity, UUID>`

---

## Mappers (opcional, MapStruct)

Si necesitas llevar entidades a objetos de dominio (p. ej. para B1/F2-06):

* `UserMapper` ‚Üí `User.ofId(entity.getId())`
* `DataFileMapper` ‚Üí construye `DataFile` del core con sus campos
* `ProcessingRequestMapper` ‚Üí crea `ProcessingRequest` del core y ajusta `status` aplicando sus transiciones (`markInProgress`, `markCompleted`, `markFailed`) seg√∫n el enum almacenado.

> `BatchJobConfig` en el core usa builder con `logicalName` y genera ID; si solo necesitas el **id** en consultas, puedes omitir su reconstrucci√≥n completa hasta B5/B6.

---

## Tests de integraci√≥n (`RepositoryIT`)

* **Tipo:** `@DataJpaTest` + **Testcontainers** (reutiliza lo de F2-07).
* **Esquema:** para esta HU, `spring.jpa.hibernate.ddl-auto=create-drop` y `spring.flyway.enabled=false` en el test. (En F2-09 migraremos a **Flyway**.)
* **Cobertura:**

    * Persistir `ProcessingRequestEntity` con `parameters` y leerlos de vuelta.
    * Crear 3 `JobExecutionEntity` con `startTime` distintos y comprobar que `findTop1ByProcessingRequestIdOrderByStartTimeDesc(...)` devuelve la √∫ltima.
    * Consulta paginada `findByStatus(...)`.

**Ejemplo de aserci√≥n de ‚Äú√∫ltima ejecuci√≥n‚Äù**

```java
var last = execs.findTop1ByProcessingRequestIdOrderByStartTimeDesc(prId).orElseThrow();
assertThat(last.getStartTime()).isEqualTo(t2).isAfter(t1).isAfter(t3);
```

---

## Configuraci√≥n de test

* Mant√©n `application-test.yml` **sin** `spring.datasource.*` (Testcontainers inyecta).
* Si tu Boot < 3.1, a√±ade `@DynamicPropertySource` en el test para mapear las props del contenedor.

---

## Criterios de aceptaci√≥n

* CRUD b√°sico para `User`, `DataFile`, `ProcessingRequest` pasa en tests de integraci√≥n.
* Query `findTopByProcessingRequestIdOrderByStartTimeDesc` devuelve la ejecuci√≥n correcta.
* Conversor JSONB funciona: inserta/lee `parameters` sin p√©rdida.

---

## Notas

* `@Repository` en interfaces de Spring Data es **opcional**.
* En B2-09 se introducir√° **Flyway** para el esquema; por ahora los tests generan tablas con Hibernate (`create-drop`).

---

# F2-09 ‚Äî Flyway baseline + JSONB y correcciones de test

> **Objetivo:** crear el **esquema inicial** con **Flyway**, mapear `JSONB` correctamente (sin acoplar `core`) y asegurar que los tests no ejecuten SQL de PostgreSQL en H2.

---

## Archivos creados/actualizados

* `api-service/src/main/resources/db/migration/postgresql/V1__baseline.sql` *(migraci√≥n base vendorizada)*
* `api-service/src/main/resources/db/migration/postgresql/V2__alter_checksum_to_varchar.sql` *(ajuste de tipos)*
* `api-service/src/main/resources/application-test.yml` *(Flyway + validate, sin datasource)*
* **Entidades (ajustes)** en `api-service`:

    * `ProcessingRequestEntity.parameters` ‚Üí `@JdbcTypeCode(SqlTypes.JSON)` + `columnDefinition = "jsonb"`
    * `UserEntity.role` ‚Üí `@Enumerated(EnumType.STRING)`; `createdAt` con `@PrePersist` para default
* **Tests**: desactivar Flyway solo en smokes que no usan BD o vendorizar migraciones

---

## Esquema con Flyway (PostgreSQL)

**`V1__baseline.sql`** (ubicaci√≥n: `db/migration/postgresql/`):

* Extensiones/Tipos Postgres
* Tablas y claves for√°neas:

    * `users (id uuid PK, name varchar(140), email varchar(140) UNIQUE NOT NULL, role varchar(32) NOT NULL, created_at timestamptz NOT NULL DEFAULT now())`
    * `data_files` (`checksum_sha256 varchar(64)`, etc.)
    * `batch_job_configs`
    * `processing_requests (parameters jsonb NOT NULL DEFAULT '{}'::jsonb)`
    * `job_executions`
    * `reports`
* √çndices:

    * `idx_pr_status_created (status, created_at DESC)`
    * `idx_je_pr_start_desc (processing_request_id, start_time DESC)`

**`V2__alter_checksum_to_varchar.sql`**:

```sql
ALTER TABLE data_files
  ALTER COLUMN checksum_sha256 TYPE varchar(64);
```

> **Nota ****`users`****:** se actualiz√≥ para reflejar tu `UserEntity` (`email` √∫nico, `role`, `created_at`).

---

## JSONB sin converter (Hibernate 6)

En `ProcessingRequestEntity`:

```java
import org.hibernate.annotations.JdbcTypeCode;
import org.hibernate.type.SqlTypes;

@JdbcTypeCode(SqlTypes.JSON)
@Column(columnDefinition = "jsonb", nullable = false)
private Map<String, String> parameters;
```

> El campo `parameters` se persiste como **jsonb** nativo; no hace falta `AttributeConverter` ni `PGobject`.

---

## Configuraci√≥n por perfil

**`application-test.yml`** (tests con Testcontainers + Flyway):

```yaml
spring:
  jpa:
    hibernate:
      ddl-auto: validate
    open-in-view: false
    properties:
      hibernate.jdbc.time_zone: UTC
  flyway:
    enabled: true
    locations: classpath:db/migration/{vendor}
    baseline-on-migrate: false
  sql:
    init:
      mode: never
logging:
  level:
    root: WARN
    org.springframework: WARN
    org.flywaydb: INFO
```

**`application-dev.yml`** (resumen):

```yaml
spring:
  datasource:
    url: ${DB_URL:jdbc:postgresql://localhost:5432/dataflow}
    username: ${DB_USER:app}
    password: ${DB_PASSWORD:secret}
    driver-class-name: org.postgresql.Driver
  jpa:
    hibernate:
      ddl-auto: validate
    properties:
      hibernate.jdbc.time_zone: UTC
  flyway:
    enabled: true
    locations: classpath:db/migration/{vendor}
    baseline-on-migrate: true
```

> Usar `{vendor}` permite que Flyway cargue `postgresql/` con Postgres y (si lo necesitas) `h2/` con H2.

---

## Estrategia de tests

* **Integraci√≥n JPA/Repos:**

    * `@DataJpaTest` + Testcontainers (PostgreSQL 16) con Flyway habilitado (`ddl-auto=validate`).
    * Verifica: persistencia de `parameters` (jsonb), query de √∫ltima `JobExecution`, paginaci√≥n por `status`.

* **Smokes sin BD (web/actuator/config):**

    * Deshabilitar Flyway en el test:

      ```java
      @SpringBootTest(properties = {
        "spring.flyway.enabled=false",
        "spring.jpa.hibernate.ddl-auto=none"
      })
      class HealthExtraControllerIT { }
      ```

* **Opcional:** si necesitas H2, crea migraciones en `db/migration/h2/` (sin `CREATE EXTENSION` ni `jsonb`) y deja `locations: classpath:db/migration/{vendor}`.

---

## Errores t√≠picos y soluci√≥n

* **Duplicated version** (`Found more than one migration with version 1`):

    * Evita tener `V1__*.sql` en `src/main/resources` y `src/test/resources` a la vez.
    * Mant√©n todas las versionadas en `main` y usa `R__*.sql` para seeds de test.

* **H2 ejecutando SQL PG** (`CREATE EXTENSION`, `jsonb`):

    * Vendoriza migraciones (`{vendor}`) o desactiva Flyway en smokes.

* **Mismatch de tipos** (`char(64)` vs `varchar(64)`):

    * Aplica `V2__alter_checksum_to_varchar.sql` o ajusta `@Column(columnDefinition = "char(64)")` (no recomendado).

---

## Verificaci√≥n

**Desarrollo (dev):**

```bash
export SPRING_PROFILES_ACTIVE=dev DB_URL=jdbc:postgresql://localhost:5432/dataflow DB_USER=app DB_PASSWORD=secret
mvn -pl api-service spring-boot:run
```

**Tests (PostgreSQL real):**

```bash
mvn -pl api-service -Dtest=RepositoryIT,DbSmokeTest test
```

Debes ver en logs: `Successfully applied V1` (+ `V2` si procede) y `ddl-auto=validate` sin errores.

---

## Criterios de aceptaci√≥n

* Migraciones Flyway aplican limpias en PostgreSQL (V1 + V2).
* `ProcessingRequestEntity.parameters` persiste/lee como **jsonb**.
* Tests de integraci√≥n pasan con Testcontainers; smokes no fallan por SQL de Postgres.
* `users` refleja `email UNIQUE`, `role` (string) y `created_at`.

---

# F2-10 ‚Äî Manejador global de errores (REST)

> **Objetivo:** unificar el **formato JSON** de errores en toda la API con un `@RestControllerAdvice`, mapear correctamente las excepciones comunes (validaci√≥n, negocio, infraestructura) y cubrirlo con tests de MVC.

---

## Archivos creados/actualizados

* `api-service/src/main/java/.../exception/RestExceptionHandler.java` *(nuevo handler global)*
* `api-service/src/test/java/.../RestExceptionHandlerTest.java` *(tests de mapeo 400/404/503/500)*
* **Elimina/sustituye** `ApiErrorHandler` previo para evitar dos `@RestControllerAdvice` en el contexto.

**Dependencias:** se reutilizan las de `api-service` (incl. `spring-boot-starter-validation`). No se tocan `core` ni `lib`.

---

## Formato de respuesta de error

```json
{
  "timestamp": "2025-08-11T03:15:29.123Z",
  "path": "/ruta",
  "code": "VALIDATION_ERROR",
  "message": "Invalid request",
  "fields": [ {"field": "title", "message": "must not be blank"} ],
  "traceId": "..."  // opcional si hay MDC/observabilidad
}
```

**Tipos auxiliares:**

* `FieldItem { field, message }`
* `ErrorResponse { timestamp, path, code, message, fields[], traceId? }`

---

## Mapeos implementados

| HTTP | code                      | Excepci√≥n manejada                                                                                                                               |
| ---- | ------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------ |
| 400  | `VALIDATION_ERROR`        | `MethodArgumentNotValidException`, `BindException`, `ConstraintViolationException`, `HttpMessageNotReadableException` *(‚Üí **`MALFORMED_JSON`**)* |
| 400  | `BUSINESS_RULE_VIOLATION` | `IllegalArgumentException` (mensajes de dominio mapeados a `fields` cuando aplica)                                                               |
| 400  | `FILE_TOO_LARGE`          | `FileTooLargeException`                                                                                                                          |
| 404  | `NOT_FOUND`               | `ResourceNotFoundException`                                                                                                                      |
| 503  | `SERVICE_UNAVAILABLE`     | `DataAccessException` (problemas de BD/infra)                                                                                                    |
| 500  | `UNEXPECTED_ERROR`        | `Exception` (catch‚Äëall)                                                                                                                          |

> **Nota:** los m√©todos `@ExceptionHandler` son **p√∫blicos**. El handler obtiene `traceId` de `MDC` si est√° disponible.

---

## Integraci√≥n con controladores

* No requieren cambios: cualquier excepci√≥n de las listadas ser√° serializada con el formato anterior.
* Para reglas de dominio que hoy lanzan `IllegalArgumentException`, el handler responde **400 BUSINESS\_RULE\_VIOLATION** y, si reconoce el mensaje, rellena `fields` (por ejemplo: `originalFilename is blank` ‚Üí `fields[originalFilename]`).

---

## Tests

### Opci√≥n A (recomendada): MockMvc standalone

Registra expl√≠citamente el controller de prueba y el advice:

```java
MockMvc mvc = MockMvcBuilders
  .standaloneSetup(new DummyController())
  .setControllerAdvice(new RestExceptionHandler())
  .build();
```

Casos cubiertos en `RestExceptionHandlerTest`:

* 400 con `fields[]` (Bean Validation)
* 404 `NOT_FOUND`
* 503 `SERVICE_UNAVAILABLE` (simulando `DataAccessException`)
* 500 `UNEXPECTED_ERROR`

### Opci√≥n B: `@WebMvcTest`

```java
@WebMvcTest(controllers = DummyController.class)
@Import(RestExceptionHandler.class)
@AutoConfigureMockMvc(addFilters = false) // si seguridad interfiere
```

> Si ves 500 en lugar de 400/404/503: confirma que el advice est√° **importado** en el slice y que los `@ExceptionHandler` son **public**.

---

## Troubleshooting

* **500 en tests de validaci√≥n:** faltaba importar el advice en `@WebMvcTest` o los `@ExceptionHandler` no eran `public`.
* **`HttpMessageNotReadableException`** por JSON malformado: se devuelve `code="MALFORMED_JSON"` con 400.
* **Tests que no usan BD fallan por Flyway/H2:** deshabilitar Flyway en esos tests (`spring.flyway.enabled=false`) o vendorizar migraciones (ver HU F2-09).

---

## Criterios de aceptaci√≥n

* Todas las respuestas de error comparten el **mismo shape** y `Content-Type: application/json`.
* Validaci√≥n ‚Üí **400** con `fields[]`.
* Recurso inexistente ‚Üí **404 NOT\_FOUND**.
* Problemas de BD ‚Üí **503 SERVICE\_UNAVAILABLE**.
* Errores no controlados ‚Üí **500 UNEXPECTED\_ERROR**.
* Tests de MVC cubren los cuatro escenarios anteriores.

---

## F2-12 ‚Äî Pruebas de integraci√≥n de seguridad

> **Objetivo:** verificar la configuraci√≥n de seguridad de la API mediante pruebas de integraci√≥n con usuarios en memoria y autenticaci√≥n b√°sica.

---

## Archivos creados/actualizados

* `api-service/src/test/java/.../SecurityIntegrationTest.java` *(nuevo test de integraci√≥n)*
* `api-service/src/main/java/.../config/SecurityConfig.java` *(configuraci√≥n de seguridad con usuarios en memoria y reglas de autorizaci√≥n)*

**Dependencias:** se utilizan las de `api-service` junto con H2 en memoria y `spring-security-test` para soporte de `MockMvc` con autenticaci√≥n.

---

## Comportamiento probado

* Endpoints p√∫blicos (por ejemplo, `/ping`, `/actuator/health`) accesibles sin autenticaci√≥n ‚Üí **200 OK**.
* Endpoints protegidos requieren credenciales v√°lidas ‚Üí **401 Unauthorized** sin autenticaci√≥n.
* Control de acceso por rol funciona correctamente (por ejemplo, endpoints solo para ADMIN ‚Üí **403 Forbidden** para usuarios USER).
* Autenticaci√≥n exitosa pero recurso inexistente ‚Üí **404 Not Found**.
* Autenticaci√≥n exitosa pero petici√≥n inv√°lida ‚Üí **400 Bad Request**.

---

## Implementaci√≥n de pruebas

* **Frameworks**: `SpringBootTest`, `MockMvc`, `JUnit 5`.
* **Autenticaci√≥n**: HTTP Basic con usuarios en memoria (`user` / `user123`, `admin` / `admin123`).
* **Base de datos**: H2 en memoria configurada para el perfil de pruebas, Flyway deshabilitado para acelerar la ejecuci√≥n.

---

## Ejecuci√≥n de las pruebas

```bash
mvn test -Dtest=SecurityIntegrationTest
```

---

## Criterios de aceptaci√≥n

* `/actuator/health` responde **200** sin auth; `/processings/**` devuelve **401** sin credenciales.
* Con `user/user123` se accede a `GET /processings/{id}`; con `admin/admin123` se accede adem√°s a endpoints `ADMIN` si los hay.
* Tests de seguridad cubren: 401, 403 y acceso v√°lido.

---

## Notas

* Para desarrollo local, CORS est√° habilitado para `http://localhost:3000`.
* Las contrase√±as se almacenan usando `BCryptPasswordEncoder`.
* La configuraci√≥n est√° definida en `SecurityConfig` y aplica tanto a entornos de producci√≥n como de prueba.
* En los tests de integraci√≥n se usan c√≥digos de estado **404** o **400** para confirmar que la autenticaci√≥n pas√≥, aunque la l√≥gica de negocio no encuentre el recurso o el body sea inv√°lido.

---

# Seguridad ‚Äî Comparativa Basic vs JWT (Bearer)

> **Objetivo:** documentar ventajas y desventajas de **Basic Auth** y **JWT (Bearer)** en la API, y proponer una **estrategia de migraci√≥n** para fases siguientes.

---

## Archivos creados/actualizados

* `docs/security-authn.md` *(este documento)*
* (Opcional PoC) `api-service/src/main/resources/application-jwt.yml` *(perfil de pruebas para resource server JWT)*

**Dependencias (PoC JWT):** `spring-boot-starter-oauth2-resource-server`.

---

## Resumen ejecutivo

* **Fase actual (F2):** **Basic Auth** ‚Äî simple, r√°pido para equipos internos y pruebas.
* **Fase siguiente (F3+):** **JWT (Bearer)** ‚Äî mejor para microservicios, propagaci√≥n entre servicios y escalabilidad.

---

## Comparativa por ejes

| Eje                     | Basic Auth                                                               | JWT (Bearer)                                                            |
| ----------------------- | ------------------------------------------------------------------------ | ----------------------------------------------------------------------- |
| **Estado**              | Env√≠a credenciales en **cada** request.                                  | Token firmado, **stateless**, con expiraci√≥n.                           |
| **Rotaci√≥n/Revocaci√≥n** | Cambiar contrase√±a del usuario.                                          | Compleja: listas negras, tokens **short‚Äëlived**, **refresh tokens**.    |
| **Tama√±o/latencia**     | Ligero, pero puede requerir lookups (si hay user service).               | Token m√°s pesado (claims), evita lookups por request.                   |
| **Microservicios**      | Cada salto debe revalidar credenciales.                                  | Facilita propagaci√≥n entre servicios con el mismo token.                |
| **Seguridad**           | Requiere **HTTPS**; credenciales sensibles en tr√°nsito con cada request. | **HTTPS** + gesti√≥n de llaves (**JWK/Issuer**) y relojes sincronizados. |
| **CSRF**                | Puede requerir protecci√≥n si se usa desde navegador.                     | APIs stateless con Bearer suelen quedar fuera de riesgo de CSRF.        |
| **Observabilidad**      | Sin claims; menos contexto.                                              | Claims (sub, scope, roles, tenant) mejoran trazabilidad.                |
| **Operaci√≥n**           | Sin gesti√≥n de llaves.                                                   | Gesti√≥n de **JWKS**, rotaci√≥n de firmas, reloj del cluster.             |

---

## Recomendaci√≥n

1. **Mantener Basic Auth en F2** (interno + pruebas) por rapidez y menor superficie de cambio.
2. **Planificar migraci√≥n a JWT en F3+** usando `spring-boot-starter-oauth2-resource-server` con validaci√≥n de tokens desde un **Issuer** (Keycloak/Okta/issuer propio).

    * Tokens **cortos** (5‚Äì15 min).
    * Rotaci√≥n de llaves (JWKS).
    * Scopes/roles en claims seg√∫n dominios de negocio.

---

## Lineamientos de dise√±o para migrar a JWT

* **Boundary de seguridad**: validar el token en el **edge** (API gateway o cada microservicio) y propagar solo claims necesarios.
* **Autorizaci√≥n**: usar anotaciones (`@PreAuthorize`) basadas en authorities/scopes extra√≠dos del token, o reglas en filtros.
* **Clock skew**: configurar tolerancia (¬±60s).
* **Errores**: mapear 401 por token inv√°lido/expirado y 403 por falta de scopes/roles.

---

## PoC opcional (resource server)

### Encabezado Bearer

```http
Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9...
```

### `application-jwt.yml` (perfil de prueba)

```yaml
spring:
  security:
    oauth2:
      resourceserver:
        jwt:
          # Elige uno de los dos enfoques
          # 1) Validaci√≥n por Issuer (OpenID Connect/Keycloak/Okta)
          issuer-uri: http://localhost:9000/realms/dataflow
          # 2) Validaci√≥n por clave p√∫blica (RSA) local
          # jwk-set-uri: http://localhost:9000/realms/dataflow/protocol/openid-connect/certs

# Activar este perfil solo en el PoC para no interferir con Basic
spring:
  profiles:
    active: jwt
```

### Dependencia (PoC)

```xml
<dependency>
  <groupId>org.springframework.boot</groupId>
  <artifactId>spring-boot-starter-oauth2-resource-server</artifactId>
</dependency>
```

### Config m√≠nima Java (si no usas autoconfig por perfil)

```java
@Bean
SecurityFilterChain jwtFilterChain(HttpSecurity http) throws Exception {
  http
    .authorizeHttpRequests(a -> a
      .requestMatchers("/actuator/health", "/ping").permitAll()
      .anyRequest().authenticated())
    .oauth2ResourceServer(o -> o.jwt());
  return http.build();
}
```

### Tests sugeridos (PoC)

* **200** con token v√°lido (firma OK y no expirado).
* **401** con token sin firma v√°lida o expirado.
* **403** con token v√°lido pero sin el scope/rol requerido.

---

## Criterios de aceptaci√≥n

* Documento `docs/security-authn.md` con **tabla comparativa** y **recomendaci√≥n clara** (Basic ahora, JWT luego).
* *(Si se realiza PoC)* existe `application-jwt.yml` y un test que demuestra **200** con token v√°lido y **401** con token inv√°lido.
* Configuraci√≥n separada por **perfil** para no interferir con Basic en `dev`.

---

## Notas

* Para producci√≥n, planificar **rotaci√≥n de llaves**, tiempos de expiraci√≥n cortos y estrategia de **refresh tokens** (si aplica a clientes de confianza).
* Considerar un **Issuer** central (Keycloak/Okta/Cognito) para estandarizar *claims*, *scopes* y rotaci√≥n de llaves.
* La migraci√≥n debe ser **compatible**: convivir temporalmente **Basic** (interno) y **JWT** (clientes externos) detr√°s de paths o perfiles distintos.
* Documentar *error codes* de autenticaci√≥n/autorizaci√≥n para los clientes (401 vs 403).

---

## F2-14 ‚Äî Actuator y M√©tricas (Micrometer)

> **Objetivo:** habilitar y verificar m√©tricas de Actuator, incluyendo m√©tricas personalizadas para el conteo de ejecuciones de Job y pruebas de su exposici√≥n.

---

## Archivos creados/actualizados

* `api-service/src/main/resources/application.yml` *(configuraci√≥n de exposici√≥n de endpoints Actuator y etiquetas de m√©tricas)*
* `api-service/src/main/java/.../metrics/JobMetrics.java` *(registro de m√©tricas personalizadas con Micrometer)*
* `api-service/src/test/java/.../HealthActuatorIT.java` *(test de integraci√≥n para /actuator/health)*
* `api-service/src/test/java/.../MetricsActuatorIT.java` *(test de integraci√≥n para /actuator/metrics y m√©tricas personalizadas)*

**Dependencias:**

* `spring-boot-starter-actuator` (endpoints de observabilidad)
* `io.micrometer:micrometer-registry-prometheus` *(opcional para exposici√≥n en Prometheus)*

---

## Comportamiento probado

* `/actuator/health` expuesto p√∫blicamente y retorna **200 OK** con estado `UP`.
* `/actuator/metrics` accesible para usuarios autenticados.
* M√©trica personalizada `dataflow.job.executions.total` presente con tags configurados (`result=success|fail`).
* Incremento del contador al simular la finalizaci√≥n de un Job.
* Validaci√≥n opcional de `/actuator/prometheus` si est√° habilitado.

---

## Implementaci√≥n de pruebas

* **Frameworks:** `SpringBootTest`, `MockMvc`, `JUnit 5`.
* **Base de datos:** H2 en memoria para pruebas, Flyway deshabilitado.
* **Flujo de test:**

    1. Llamar a `/actuator/health` y verificar estado `UP`.
    2. Consultar `/actuator/metrics/dataflow.job.executions.total` y validar presencia de `measurements`.
    3. Simular incremento de contador y verificar cambio.

---

## Ejecuci√≥n de las pruebas

```bash
mvn test -Dtest=HealthActuatorIT,MetricsActuatorIT
```

---

## Criterios de aceptaci√≥n

* `/actuator/metrics` y `/actuator/health` expuestos seg√∫n perfil.
* `dataflow.job.executions.total` visible y se incrementa en pruebas.
* `/actuator/prometheus` devuelve series con prefijo `dataflow_` si est√° habilitado.
* Documentaci√≥n breve en README sobre consulta y significado de m√©tricas.

---

## Notas

* En desarrollo, configurar cuidadosamente Actuator para no exponer informaci√≥n sensible.
* Tag `application` definido como `dataflowhub-api` para dashboards.
* Con Prometheus habilitado, `/actuator/prometheus` puede ser consumido por Prometheus o APM compatible.

---

## F2-15 ‚Äî Logs Estructurados (JSON) con traceId

> **Objetivo:** habilitar logs en formato JSON que incluyan `traceId` para mejorar la trazabilidad y facilitar la integraci√≥n con herramientas de an√°lisis de logs.

---

## Archivos creados/actualizados

* `api-service/src/main/resources/logback-spring.xml` *(configuraci√≥n para salida JSON con traceId/spandId en cada evento)*
* `api-service/src/test/java/.../StructuredLoggingIT.java` *(test de integraci√≥n para validar formato y campos clave)*
* Configuraci√≥n por perfil en `application.yml` y `application-dev.yml` para niveles de logging.

**Dependencias:**

* Opci√≥n A: `net.logstash.logback:logstash-logback-encoder` para JSON estructurado.
* Opci√≥n B: Patr√≥n JSON manual con `%mdc` (sin encoder externo).

---

## Comportamiento implementado

* Logs en formato JSON en entornos **dev** y **prod**.
* Inclusi√≥n autom√°tica de `traceId` y `spanId` en cada evento.
* Niveles de log configurables por perfil (`DEBUG` en dev, `INFO` en prod).
* Integraci√≥n opcional con Micrometer Tracing para poblar autom√°ticamente el `traceId`.
* Filtro `OncePerRequestFilter` para generar y propagar `traceId` cuando no exista.

---

## Ejemplo de log generado

```json
{
  "timestamp": "2025-08-11T05:25:10.111Z",
  "level": "INFO",
  "logger": "com.dataflowhub.api.web.ProcessingController",
  "traceId": "f9f1a2b3c4d5e67fa",
  "message": "ProcessingRequest created",
  "requestId": "7e2a1d7c-3b9b-4f1a-8a55-9a2f1e4c7788",
  "user": "user@acme.com"
}
```

---

## Ejecuci√≥n de las pruebas

```bash
mvn test -Dtest=StructuredLoggingIT
```

---

## Criterios de aceptaci√≥n

* Logs en JSON en **dev/prod** con `traceId` presente.
* Control de niveles por perfil (`DEBUG` en dev, `INFO` en prod).
* Tests validan presencia de campos clave (`traceId`, `message`).
* README de "Observabilidad" documenta c√≥mo visualizar `/actuator/*` y ejemplo de log JSON.

---

## Notas

* No incluir datos sensibles en los logs.
* Se recomienda incluir campos de contexto como: `requestId`, `user`, `endpoint`.
* Niveles: `INFO` normal, `WARN` recuperable, `ERROR` con stacktrace.

---

## F2-16 ‚Äî Lanzar Job Batch v√≠a REST (`POST /jobs/{id}/run`)

> **Objetivo:** permitir la ejecuci√≥n bajo demanda de un Job de Spring Batch v√≠a un endpoint REST seguro y restringido a administradores.

---

## Archivos creados/actualizados

* `api-service/src/main/java/.../rest/JobController.java` *(nuevo controlador para ejecutar Jobs v√≠a REST)*
* `api-service/src/test/java/.../JobControllerTest.java` *(tests unitarios)*
* Configuraci√≥n de Spring Batch en perfiles `dev`, `test` y `prod` (`application-*.yml`).

**Dependencias:** `spring-boot-starter-batch` (solo en `api-service`).

---

## Comportamiento implementado

* Endpoint `POST /jobs/{configId}/run` protegido con rol **ADMIN**.
* Construcci√≥n de `JobParameters` con:

    * `processingRequestId` (UUID como String)
    * `configId` (desde el path)
    * `requestTime` (Instant en ISO-8601 o epoch para asegurar unicidad)
* Uso de `JobLauncher.run(job, params)` para iniciar el Job y retorno **202 Accepted** con:

    * Header `Location` apuntando a `/processings/{processingRequestId}`
    * Body con `jobInstanceId` y `jobExecutionId`.
* Control de concurrencia: si existe una ejecuci√≥n `RUNNING` con los mismos par√°metros clave, responde **409 Conflict** con c√≥digo `JOB_ALREADY_RUNNING`.
* Registro de m√©tricas personalizadas (`dataflow.job.executions.total`).
* Manejo de errores:

    * Config desconocido ‚Üí **404 CONFIG\_NOT\_FOUND**
    * Error de infraestructura ‚Üí **503**

---

## Ejecuci√≥n de pruebas

* **Unitarias:** Mock de `JobLauncher` para verificar construcci√≥n de `JobParameters` y respuesta 202.
* **Integraci√≥n:** con Spring Batch activo, ejecuta un Job dummy y verifica registros en tablas `BATCH_*`.

```bash
mvn test -Dtest=JobControllerTest
```

---

## Ejemplo de uso

**Request (m√≠nimo):**

```http
POST /jobs/csv_to_ipa_v1/run
Content-Type: application/json

{
  "processingRequestId": "7e2a1d7c-3b9b-4f1a-8a55-9a2f1e4c7788",
  "parameters": { "delimiter": ";" }
}
```

**Response (202):**

```json
{
  "jobInstanceId": 123,
  "jobExecutionId": 456
}
```

**Conflicto si ya corre ‚Üí 409:**

```json
{
  "code": "JOB_ALREADY_RUNNING"
}
```

---

## Criterios de aceptaci√≥n

* Endpoint protegido (ADMIN) retorna 202 y `Location` v√°lido.
* Si existe ejecuci√≥n RUNNING con mismos par√°metros clave ‚Üí 409.
* Spring Batch crea registros en tablas `BATCH_*` o mock verificado en unit test.
* M√©trica `dataflow.job.executions.total` incrementa al aceptar.

---

## Notas

* **Perfiles:** en `dev` y `test` usar H2; en `prod` conectar a base persistente.
* **Persistencia:** esquema JDBC de Spring Batch se autoinicializa en `dev/test`; en `prod` incluir en Flyway.
* **Seguridad:** restringido a rol `ADMIN` seg√∫n configuraci√≥n de `SecurityConfig`.
* **M√©tricas:** visibles v√≠a `/actuator/metrics/dataflow.job.executions.total`.

---

## F2-17 ‚Äî Scheduler diario con `@EnableScheduling` (02:00 en `prod`)

> **Objetivo:** Automatizar la ejecuci√≥n diaria de Jobs Batch a las 02:00 en el entorno de producci√≥n, con control de concurrencia, m√©tricas y logs estructurados.

---

## Archivos creados/actualizados

* `api-service/src/main/java/.../BatchScheduler.java` *(nuevo scheduler)*
* `application-prod.yml` *(propiedad `scheduling.enabled=true`)*
* `application-dev.yml` y `application-test.yml` *(propiedad `scheduling.enabled=false`)*

**Dependencias:** uso de `spring-context` para `@EnableScheduling` y `@Scheduled`.

---

## Comportamiento implementado

* El scheduler se activa √∫nicamente en perfil **`prod`** gracias a la propiedad `scheduling.enabled=true`.
* A las **02:00** se ejecuta el m√©todo planificado (`@Scheduled(cron = "0 0 2 * * *")`).
* Consulta en la base de datos todas las solicitudes de procesamiento (`ProcessingRequest`) con estado **PENDING** (m√°x. 50 por ciclo).
* Para cada solicitud, invoca internamente el mismo servicio que expone el endpoint `/jobs/{configId}/run` de la HU F2-16.
* Verifica mediante `JobExplorer` que no exista ya una ejecuci√≥n **RUNNING** para el mismo `processingRequestId`.
* Implementa control de back-pressure: si hay m√°s de `N` ejecuciones en estado **RUNNING**, pospone el resto.
* Registra en m√©tricas (`dataflow.scheduler.trigger{result=launched|skipped}`) y logs (`traceId`) el resultado de cada ejecuci√≥n.

---

## Ejecuci√≥n del Scheduler

* **Prod:** activo a las 02:00.
* **Dev/Test:** desactivado (`scheduling.enabled=false`).

---

## Ejemplos

**application-prod.yml**

```yaml
scheduling:
  enabled: true
```

**Log esperado (JSON)**

```json
{
  "message": "Scheduler launched 17 jobs",
  "result": "launched",
  "pending": 23,
  "launched": 17,
  "skipped": 6,
  "traceId": "f91fa2b3c4d5e67a"
}
```

---

## Criterios de aceptaci√≥n

* Con `scheduling.enabled=true` en **prod**, el m√©todo se ejecuta a las **02:00**.
* No lanza un job si ya hay una ejecuci√≥n **RUNNING** para el mismo `processingRequestId`.
* M√©trica `dataflow.scheduler.trigger` visible en `/actuator/metrics`.
* Tests unitarios verifican el comportamiento en ambos perfiles.

---

## Notas

* En entornos locales, mantener `scheduling.enabled=false` para evitar ejecuciones involuntarias.
* La implementaci√≥n actual est√° preparada para integrarse con el flujo real de ejecuci√≥n de jobs definido en la HU F2-16.
* Los logs incluyen `traceId` para permitir trazabilidad completa de ejecuciones.

---

## F2-20 ‚Äî Configuraci√≥n de despliegue con Docker

> **Objetivo:** preparar la aplicaci√≥n `api-service` para ser empaquetada y ejecutada en contenedores Docker, incluyendo configuraci√≥n para PostgreSQL y perfiles de ejecuci√≥n.

---

## Archivos creados/actualizados

* `Dockerfile` *(nuevo)* ‚Äî Construcci√≥n multi-stage (JDK para compilaci√≥n, JRE para ejecuci√≥n) con empaquetado optimizado.
* `docker-compose.yml` *(nuevo)* ‚Äî Orquestaci√≥n de `api-service` y base de datos PostgreSQL.
* Configuraci√≥n en `application.properties` para soportar variables de entorno y perfiles (`prod`, `dev`, `test`).

**Dependencias:**

* Imagen base `eclipse-temurin` (Java 21).
* PostgreSQL 16-alpine.

---

## Comportamiento esperado

* Construcci√≥n del JAR mediante **multi-stage build**:

    1. Etapa de compilaci√≥n con Maven y JDK 21.
    2. Etapa final con JRE 21 y el `app.jar` listo para ejecutar.
* Ejecuci√≥n en contenedor con variables de entorno para DB y perfil activo.
* Orquestaci√≥n con `docker-compose` que levanta la app y PostgreSQL en red compartida.
* Posibilidad de usar `host.docker.internal` para conectar a PostgreSQL local en entornos sin Compose.

---

## Ejecuci√≥n de pruebas

### 1) Solo la imagen de la app (sin DB)

```bash
docker build -t dataflowhub/api-service .
docker run --rm -p 8080:8080 \
  -e SPRING_PROFILES_ACTIVE=prod \
  -e SPRING_FLYWAY_ENABLED=false \
  -e SPRING_DATASOURCE_URL='jdbc:h2:mem:testdb;MODE=PostgreSQL' \
  dataflowhub/api-service
```

### 2) App + DB con Docker Compose

```bash
docker compose up --build
```

Esto levanta PostgreSQL (`db`) y `api-service` conectados en la misma red Docker.

### 3) App conectando a DB local

```bash
docker run --rm -p 8080:8080 \
  -e SPRING_DATASOURCE_URL='jdbc:postgresql://host.docker.internal:5432/dataflow' \
  -e SPRING_DATASOURCE_USERNAME=app \
  -e SPRING_DATASOURCE_PASSWORD=secret \
  dataflowhub/api-service
```

---

## Ejemplo de configuraci√≥n `docker-compose.yml`

```yaml
services:
  db:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: dataflow
      POSTGRES_USER: app
      POSTGRES_PASSWORD: secret
    ports:
      - "5432:5432"

  api:
    build: .
    environment:
      SPRING_PROFILES_ACTIVE: prod
      SPRING_DATASOURCE_URL: jdbc:postgresql://db:5432/dataflow
      SPRING_DATASOURCE_USERNAME: app
      SPRING_DATASOURCE_PASSWORD: secret
    ports:
      - "8080:8080"
    depends_on:
      - db
```

---

## Criterios de aceptaci√≥n

* Se puede construir la imagen del servicio con `docker build` sin errores.
* La aplicaci√≥n inicia correctamente en contenedor usando DB en Compose.
* Se soporta conexi√≥n a DB local o en otro contenedor usando variables de entorno.
* El empaquetado multi-stage reduce el tama√±o final de la imagen.

---

## Notas

* En Windows/Mac, `host.docker.internal` apunta al host; en Linux puede requerir configuraci√≥n adicional.
* Flyway est√° habilitado en `prod` por defecto; deshabilitar (`SPRING_FLYWAY_ENABLED=false`) si no se desea migrar en contenedor.
* Para desarrollo, se recomienda mapear `application.properties` externos como volumen para ajustes r√°pidos sin reconstruir la imagen.

---

